{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La régression logistique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position du problème: classification binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régression logistique permet de résoudre des problèmes de classification binaire de données. Le problème consiste à répondre si oui ou non une variable appartient à l'une de deux classes. Pour cela, on donne aux deux classes les étiquettes 0 et 1. Les données prédites prennent alors les valeurs 0 ou 1 suivant leur probabilité et se répartissent ainsi dans les deux classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La fonction logistique ou fonction de répartition de la loi logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est la fonction logistique (de la famille des fonctions sigmoïdes) qui se prête au mieux au problème de classification binaire de données. Cette fonction ne peut prendre que des valeurs se trouvant entre 0 et 1. Son expression standard est:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(z)=\\frac{1}{1+e^{-z}}    \n",
    "\\label{eq1}\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "Dans le cas de la régression logistique, la fonction $\\eqref{eq1}$ encapsule le polynôme de régression de la forme \n",
    "\n",
    "\\begin{equation}\n",
    "f(X)=WX+b\n",
    "\\label{eq2}\\tag{2}\n",
    "\\end{equation}\n",
    "où W est le vecteur des Poids et b le Biais.\n",
    "\n",
    "La fonction $\\eqref{eq1}$ devient \n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(W)=\\frac{1}{1+e^{-(WX+b)}}    \n",
    "\\label{eq3}\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "W et b sont les paramètres à optimiser. Dans la pratique, on ajoute une colonne de biais $x_0=[1 1 ... 1]$ à la matrice des variables (\"features\") X et on écrit la fonction $\\eqref{eq3}$ ainsi\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(W)=\\frac{1}{1+e^{-WX}}    \n",
    "\\label{eq4}\\tag{4}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation des paramètres: descente du gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres optima sont des paramètres qui permettent d\\'obtenir la fonction de coût la plus minimale possible. La fonction de coût est la somme des carées des écarts entre les valeurs prédites et les valeurs observées. Dans le cas de la focntion logistique, la fonction de coût est donnée par l'expression:\n",
    "\n",
    "\\begin{equation}\n",
    "J(W)=-\\frac{1}{m}\\sum Y\\times \\log(\\sigma(W))+(1-Y)\\times \\log(1-\\sigma(W))    \n",
    "\\label{eq5}\\tag{5}\n",
    "\\end{equation}\n",
    "où W, X, Y sont respectivement la matrice des paramètres à optimiser, la matrice des variables (\"features\") et la matrice des données cibles (\"target\").\n",
    "Le gradient (dérivée première de la fonction J(W) par rapport aux variables du vecteur W) de cette fonction est donée par l'expression\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial J(W)}{\\partial W}=\\frac{1}{m}X^{T}(\\sigma(W)-Y)\n",
    "\\label{eq6}\\tag{6}\n",
    "\\end{equation}\n",
    "\n",
    "La minimisation de la fonction de coût se fait par la mise à  jour des paramètres W à chaque itération de telle manière que le coût soit plus petit par rapport à celui de l'itération précédente. La mise à jour se fait suivant l'expression:\n",
    "\n",
    "\\begin{equation}\n",
    "W=W-\\alpha\\frac{\\partial J(W)}{\\partial W}\n",
    "\\label{eq7}\\tag{7}\n",
    "\\end{equation}\n",
    "$\\alpha$ est appelée \"learning rate\" et est chosi de telle manière que le pas soit ni trop grand (pour éviter le risque d'absence de convergence) ni trop petit (pour éviter que le calcul soit trop lent). Le calcul itératif s'arrête si la convergence est atteinte ou si le nombre maximum d'itérations fixé préalablement est atteint.\n",
    "\n",
    "La figure ci-dessous montre la variation du coût en fonction du nombre d'itérations\n",
    "![Coût en fonction du nombre d'interations](fonction_cout.png \"ShowMyImage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L\\'entrainement du modèle consiste à rechercher les paramètres W pour lesquels le coût est le plus minimal possible. La pratique consiste séparer les données en deux. Une partie (80\\%) est utilisée pour entrainer le modèle et une autre (20\\%) est réservée pour le test du modèle.\n",
    "\n",
    "A l'aide la bibliothèque **scikit-lean**, cette opération peut être effectuée en utilsant la fonction **train_test_split()**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2,random_state=5)\n",
    "```\n",
    "X et Y sont respectivement la matrice des variables et la matrice des données cibles. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice **X_train** est alors utilisée à la place de la matrice X dans la fonction $\\sigma(W)$ dans le processus de minimisation de la fonction de coût."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après l'entrainement du modèle, il faut tester sa fiabilité. On utilise la seconde partie du jeu de données, ici **X_test**, pour effectuer des calculs de prévision de la variable Y sur les paramètres **W** obtenus à la fin du processus d\\'entrainement du modèle. Les prévisions obtenues **Y_pred** sont des probabilités qu'il faut transformer sous forme de valeurs 0 ou 1 dans le cas d'une classification binaire. La méthode usuelle consiste à fixer le seuil à 50\\%. Si la probabilité est inférieure à 0.5, **Y_pred** devient 0 et si la probalité est supérieure à 0.5, **Y_pred** devient 1 (la fonction **round()** de Python peut être utilisée pour effectuer cette transformation). Ainsi, les données de la prédiction sont séparées en deux classes d'étiquettes 0 ou 1 et peuvent être comparées aux données de la cible **Y_test**. Plusieurs valeurs métriques peuvent être calculées pour mesurer la performance du modèle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion (\"confusion matrix\" en anglais) est un outil puissant pour montrer la performance du modèle. Elle permet de visualiser le nombre de données classées correctement et le nombre de données sur lesquelles le modèle se trompe. Les données sont classées dans quatre catégories: la catégorie **\"vrai positive (TP)\"** si la prévision est 1 alors que la donnée cible observée est 1, la catégorie **\"vrai négative (TN)\"** si la prévision est 0 alors que la donnée cible observée est 0, la catégorie **\"faut positive (FP)\"** si la prévision est 1 alors que la donnée cible observée est 0 et la catégorie **\"faut négative (FN)\"** si la prévision est 0 alors que la donnée cible observée est 1. La matrice de confusion peut être résumée dans le tableau suivant:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|||Matrice de confusion | |\n",
    "|---|---| --- | --- |\n",
    "|||**<font color='green'>Prédite</font>**| |\n",
    "||| **Negative** | **Positive**|\n",
    "||**Negative**| Vrai négative | Faux négative |\n",
    "|**<font color='green'>Actuelle</font>**||  | |\n",
    "||**Positive**|Faux positive | Vrai positive|\n",
    "\n",
    "Le modèle est d'autant plus performant que le nombre des \"faux positives\" et des \"faux négatives\" est petit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C\\'est la fraction de données prédite correctement. Elle est le rapport entre le nombre de données prédites correctement (\"vrais positives\" et \"vrais négatives\" ) et le nombre totale de données:\n",
    "\n",
    "\\begin{equation}\n",
    "Accuracy=\\frac{TP+TN}{TP+FP+TN+FN}\n",
    "\\label{eq8}\\tag{8}\n",
    "\\end{equation}\n",
    "Le modèle est d'autant plus performant que cette valeur est proche de 1. La valeur peut être calculée à l'aide de la fonction **accuracy_score()** de **scikit-learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivité (recall score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sensitivité permet de calculer la fraction de données prédites positives ou négatives qui le sont dans les mesures observées. En effet, parmi les données prédites \"**positives**\", on y trouve à la fois les données \"vrais positives\" et les données \"faux négatives\".\n",
    "La sensibité est alors calculée:\n",
    "\\begin{equation}\n",
    "recall=\\frac{TP}{TP+FN}\n",
    "\\label{eq9}\\tag{9}\n",
    "\\end{equation}\n",
    "\n",
    "La fonction de **scikit-learn** pour calculer la sensitivité est **recall_score()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette valeur mesure la fraction de données positives ou négatives qui sont prédites comme tel. En effet, parmi les données \"**positives**\" par exemple, certaines peuvent être classées \"vrais positives\" et d'autres \"faux positives\".\n",
    "On a alors:\n",
    "\\begin{equation}\n",
    "precision=\\frac{TP}{TP+FP}\n",
    "\\label{eq10}\\tag{10}\n",
    "\\end{equation}\n",
    "Dans la bibliothèque **scikit-learn**, c'est  la fonction **precision_score()** qui est utilisée pour calculer cette valeur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette valeur est la moyenne harmonique de \"**recall**\" et \"**precision score**\". Elle est calculée ainsi:\n",
    "\n",
    "\\begin{equation}\n",
    "f1=\\frac{2\\times precision\\times recall}{precision+recall}\n",
    "\\label{eq11}\\tag{11}\n",
    "\\end{equation}\n",
    "\n",
    "Le modèle est d'autant perfomant que le \"**f1 score**\" est proche de 1.\n",
    "\n",
    "Dans **sciki-learn**, la fonction **f1 score()** permet de calculer cette valeur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La courbe ROC et la valeur AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La courbe ROC (Receiver Operating Characteristic) est une courbe qui permet d'illustrer les performances du modèle en comparant les taux de données classées \"vrais positives\" (TPR = true positive rate) et celui des données classées \"faux positives\" (FPR = false positive rate). Le modèle parfait est celui où le TPR = 1 tandis que le FPR = 0. Pour le modèle aléatoire, on a TPR = FPR. Un bon modèle est donc celui qui est le plus éloigné du modèle aléatoire pour s'approcher du modèle parfait.\n",
    "\n",
    "La valeur AUC (Area Under the Curve) est la valeur de l'aire sous la courbe du modèle. Le modèle est d'autant plus performant que cette valeur est importante. Un exemple est montré sur la figure ci-dessous pour un modèle de régression logistique.\n",
    "\n",
    "![Coût en fonction du nombre d'interations](ROC_AUC.png \"ShowMyImage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régression logistique permet de résoudre un problème de classification. La méthode prédit la probabilité d'un évément en utilisant la fonction de répartition de la loi logistique qui constitue le modèle. Les paramètres du modèle sont les coefficients du polynôme de régression qui est encapsulé dans la fonction logistique. Ces paramètres sont obtenues en entrainant le modèle sur les données observées par la méthode de descente de gradient.\n",
    "Cette probabilité est convertie (par exemple par arrondi) en 0 ou 1. Les deux valeurs constituent ainsi les étiquettes des deux classes séparées et les événements seront classées dans l'une ou l'autre suivant leur probabilité. La performence du modèle est évaluée par le nombre de données classées correctement dans les deux classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
